{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pba.parse as ps\n",
    "from pba.prediction import Prediction, Response\n",
    "from pba.task import MeanCredencePredictor, RandomPredictor, BaseRatePredictor, FeaturePredictor, evaluate\n",
    "from pba.features import calc_features\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9613/9613 [00:54<00:00, 177.97it/s]\n",
      "100%|██████████| 1202/1202 [00:07<00:00, 157.46it/s]\n",
      "100%|██████████| 1201/1201 [00:06<00:00, 184.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9613, 1202, 1201)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid, test = [ps.load_json_to_predictions(f\"../data/{ftype}-predictions.json\") \n",
    "                      for ftype in [\"train\", \"valid\", \"test\"]]\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomPredictor : 0.3302662469263891\n",
      "BaseRatePredictor : 0.24546528838674808\n",
      "MeanCredencePredictor : 0.20771826713514627\n",
      "FeaturePredictor : 0.24106391068826172\n",
      "FeaturePredictor : 0.19924006395263805\n"
     ]
    }
   ],
   "source": [
    "random_predictor = RandomPredictor()\n",
    "base_rate_predictor = BaseRatePredictor()\n",
    "mean_credence = MeanCredencePredictor()\n",
    "feature_predictor = FeaturePredictor([\"politics\", \"personal\", \"money\", \"negative_formulation\", \"time_until_known\"])\n",
    "feature_and_avg = FeaturePredictor([\"politics\", \"personal\", \"money\", \"negative_formulation\", \"time_until_known\", \"avg_credence\"])\n",
    "for model in [random_predictor, base_rate_predictor, mean_credence, feature_predictor, feature_and_avg]:\n",
    "    print(model.__class__.__name__, \":\", evaluate(model, train, valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03, 0.01, 0.02, 0.1, -0.01, 0.88]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(x, 2) for x in feature_and_avg.predictor.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3672"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*18*68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(r,  index=\"number\", columns=[\"number\", \"outcome\", \"politics\", \"personal\", \"money\", \"negative_formulation\", \"time_until_known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions[1].responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_responses(predictions[1]).responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1].responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0,-1,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.clip(arr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pba] *",
   "language": "python",
   "name": "conda-env-.conda-pba-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
